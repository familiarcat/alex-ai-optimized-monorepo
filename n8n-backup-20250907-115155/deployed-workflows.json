{
  "createdAt": "2025-08-27T04:27:24.901Z",
  "updatedAt": "2025-08-28T07:56:42.000Z",
  "id": "36KPle5mPiMaazG6",
  "name": "Crew - Lieutenant Uhura - Communications & I/O Operations Officer",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "crew-lieutenant-uhura",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "82121549-849d-40b7-9e45-4c5e5c0c5d13",
      "name": "Lieutenant Uhura Directive",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "bf8250ce-9a8a-4ee3-a934-bc41abc8b1dd"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories?crew_member=eq.Lieutenant Uhura",
        "options": {}
      },
      "id": "b57a7a71-c27f-4a73-8cfe-d2c6b75ce550",
      "name": "Lieutenant Uhura Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "8a44b297-dd95-4dae-9f9b-9fe2443439a6",
      "name": "LLM Selection Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        336
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "7c527b48-4121-4bcb-90a0-aea8bb5e32b0",
      "name": "Lieutenant Uhura AI Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        688,
        304
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "edc393a1-0a8f-4deb-8c73-e04da860ddb6",
      "name": "Lieutenant Uhura Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "2234d313-0b86-411a-b6b1-571660626cbc",
      "name": "Observation Lounge Communication",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        304
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ { \"crew_member\": \"Lieutenant Uhura\", \"response\": $json.choices[0].message.content, \"timestamp\": new Date().toISOString() } }}",
        "options": {}
      },
      "id": "03b4c2e3-5399-452e-96c5-326e416a06f2",
      "name": "Lieutenant Uhura Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1136,
        304
      ]
    }
  ],
  "connections": {
    "82121549-849d-40b7-9e45-4c5e5c0c5d13": {
      "main": [
        [
          {
            "node": "b57a7a71-c27f-4a73-8cfe-d2c6b75ce550",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "8a44b297-dd95-4dae-9f9b-9fe2443439a6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "b57a7a71-c27f-4a73-8cfe-d2c6b75ce550": {
      "main": [
        [
          {
            "node": "7c527b48-4121-4bcb-90a0-aea8bb5e32b0",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "8a44b297-dd95-4dae-9f9b-9fe2443439a6": {
      "main": [
        [
          {
            "node": "7c527b48-4121-4bcb-90a0-aea8bb5e32b0",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "7c527b48-4121-4bcb-90a0-aea8bb5e32b0": {
      "main": [
        [
          {
            "node": "edc393a1-0a8f-4deb-8c73-e04da860ddb6",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "2234d313-0b86-411a-b6b1-571660626cbc",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "edc393a1-0a8f-4deb-8c73-e04da860ddb6": {
      "main": [
        [
          {
            "node": "03b4c2e3-5399-452e-96c5-326e416a06f2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "2234d313-0b86-411a-b6b1-571660626cbc": {
      "main": [
        [
          {
            "node": "03b4c2e3-5399-452e-96c5-326e416a06f2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Lieutenant Uhura Directive": {
      "main": [
        [
          {
            "node": "Lieutenant Uhura Memory Retrieval",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Lieutenant Uhura Memory Retrieval": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Selection Agent": {
      "main": [
        [
          {
            "node": "Lieutenant Uhura AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Lieutenant Uhura AI Agent": {
      "main": [
        [
          {
            "node": "Observation Lounge Communication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Observation Lounge Communication": {
      "main": [
        [
          {
            "node": "Lieutenant Uhura Memory Storage",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Lieutenant Uhura Memory Storage": {
      "main": [
        [
          {
            "node": "Lieutenant Uhura Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "callerPolicy": "workflowsFromSameOwner",
    "executionOrder": "v0"
  },
  "staticData": null,
  "meta": null,
  "pinData": {},
  "versionId": "f701c8db-5724-4d7b-9b58-7f019a4999f7",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T04:27:24.902Z",
      "updatedAt": "2025-08-27T04:27:24.902Z",
      "role": "workflow:owner",
      "workflowId": "36KPle5mPiMaazG6",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-09-05T09:49:27.281Z",
  "updatedAt": "2025-09-05T09:50:47.000Z",
  "id": "58B6WvShXJ7bj8Ni",
  "name": "Alex AI Job Opportunities - Production",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "alex-ai-job-opportunities",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        300
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ { \"data\": [], \"total\": 0, \"message\": \"Alex AI Job Opportunities - Production endpoint working\", \"timestamp\": new Date().toISOString() } }}"
      },
      "id": "respond-success",
      "name": "Respond Success",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        460,
        300
      ]
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [
        [
          {
            "node": "Respond Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "e4efcbf1-d462-4dba-b0df-4b2f2c0e4fbc",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-09-05T09:49:27.283Z",
      "updatedAt": "2025-09-05T09:49:27.283Z",
      "role": "workflow:owner",
      "workflowId": "58B6WvShXJ7bj8Ni",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T02:25:45.931Z",
  "updatedAt": "2025-08-27T04:08:13.000Z",
  "id": "AeoHsSbJAXbWSs8Y",
  "name": "System - Federation Concise Agency - OpenRouter Crew",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "path": "082503f8-8939-40c4-9620-81e3eff05d82",
        "options": {}
      },
      "id": "federation_directive",
      "name": "Federation Directive Receiver",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "082503f8-8939-40c4-9620-81e3eff05d82"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_storage",
      "name": "Federation Concise Agency Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_retrieval",
      "name": "Federation Concise Agency Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "response_handler",
      "name": "Response Handler",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        464,
        304
      ]
    }
  ],
  "connections": {
    "Federation Directive Receiver": {
      "main": [
        [
          {
            "node": "Response Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Federation Concise Agency Memory Storage": {
      "main": [
        [
          {
            "node": "Federation Concise Agency Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "d1b8b297-b0a1-4f05-a120-74ddede571b1",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T02:25:45.933Z",
      "updatedAt": "2025-08-27T02:25:45.933Z",
      "role": "workflow:owner",
      "workflowId": "AeoHsSbJAXbWSs8Y",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T02:25:47.297Z",
  "updatedAt": "2025-08-27T04:08:02.000Z",
  "id": "BdNHOluRYUw2JxGW",
  "name": "Crew - Captain Jean-Luc Picard - Strategic Leadership & Mission Command",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "crew-captain-jean-luc-picard",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "crew_directive",
      "name": "Captain Jean-Luc Picard Directive",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "c5ec3bfb-001d-45d5-a6c3-9115c0b0cc0d"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_retrieval",
      "name": "Captain Jean-Luc Picard Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "llm_selector",
      "name": "LLM Selection Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        336
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "crew_ai",
      "name": "Captain Jean-Luc Picard AI Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        688,
        304
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_storage",
      "name": "Captain Jean-Luc Picard Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "observation_communication",
      "name": "Observation Lounge Communication",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        304
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "crew_response",
      "name": "Captain Jean-Luc Picard Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1120,
        304
      ]
    }
  ],
  "connections": {
    "Captain Jean-Luc Picard Directive": {
      "main": [
        [
          {
            "node": "Captain Jean-Luc Picard Memory Retrieval",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Selection Agent": {
      "main": [
        [
          {
            "node": "Captain Jean-Luc Picard AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Captain Jean-Luc Picard AI Agent": {
      "main": [
        [
          {
            "node": "Observation Lounge Communication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Observation Lounge Communication": {
      "main": [
        [
          {
            "node": "Captain Jean-Luc Picard Memory Storage",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Captain Jean-Luc Picard Memory Retrieval": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Captain Jean-Luc Picard Memory Storage": {
      "main": [
        [
          {
            "node": "Captain Jean-Luc Picard Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "aea1d25a-b20d-44ee-8cb7-3a0b4f6a8cb6",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T02:25:47.298Z",
      "updatedAt": "2025-08-27T02:25:47.298Z",
      "role": "workflow:owner",
      "workflowId": "BdNHOluRYUw2JxGW",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-09-03T00:07:17.204Z",
  "updatedAt": "2025-09-03T00:07:30.346Z",
  "id": "C5Kq9nZTnZEc0EWo",
  "name": "Enhanced Unified AI Controller - Cursor + Claude + OpenRouter",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "enhanced-unified-ai",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "cursor-webhook-trigger",
      "name": "Cursor AI Controller Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        300
      ],
      "webhookId": "enhanced-unified-ai-webhook"
    },
    {
      "parameters": {
        "jsCode": "// Enhanced input validation for Cursor + Claude + OpenRouter integration\nconst inputData = $input.all()[0].json;\n\n// Validate required fields\nif (!inputData.task_description) {\n  throw new Error('task_description is required');\n}\n\n// Extract task context and determine routing strategy\nconst context = inputData.context || {};\nconst budgetConstraints = inputData.budget_constraints || { max_cost: 0.10 };\nconst cursorContext = inputData.cursor_context || {};\nconst claudeCrewContext = inputData.claude_crew_context || {};\n\n// Determine if this should go to local Claude agents or OpenRouter\nconst shouldUseLocalClaude = context.use_local_claude || false;\nconst taskComplexity = context.task_complexity || 'medium';\nconst taskType = context.task_type || 'general';\n\n// Prepare enhanced data structure for unified processing\nreturn {\n  // Core task information\n  task_description: inputData.task_description,\n  task_type: taskType,\n  task_complexity: taskComplexity,\n  \n  // Context information\n  context: context,\n  cursor_context: cursorContext,\n  claude_crew_context: claudeCrewContext,\n  \n  // Routing decisions\n  routing_strategy: {\n    use_local_claude: shouldUseLocalClaude,\n    use_openrouter: !shouldUseLocalClaude,\n    fallback_strategy: 'openrouter'\n  },\n  \n  // Budget and constraints\n  budget_constraints: budgetConstraints,\n  \n  // Metadata\n  timestamp: new Date().toISOString(),\n  request_id: $node[\"cursor-webhook-trigger\"].json.request_id || Date.now().toString(),\n  source: 'cursor_extension'\n};"
      },
      "id": "enhanced-input-validator",
      "name": "Enhanced Input Validator & Router",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        460,
        300
      ]
    },
    {
      "parameters": {
        "jsCode": "// Route to local Claude agents or OpenRouter based on task complexity and type\nconst routingData = $input.all()[0].json;\nconst { routing_strategy, task_complexity, task_type } = routingData;\n\n// Decision logic for routing\nlet targetSystem = 'openrouter';\nlet reasoning = '';\n\nif (routing_strategy.use_local_claude) {\n  // Use local Claude agents for:\n  // - Strategic planning (Captain Picard)\n  // - Complex analysis (Commander Data)\n  // - System architecture (Geordi La Forge)\n  if (['strategic_planning', 'complex_analysis', 'system_architecture'].includes(task_type)) {\n    targetSystem = 'local_claude';\n    reasoning = `Task type '${task_type}' with ${task_complexity} complexity - routing to local Claude crew`;\n  }\n}\n\n// Always use OpenRouter for:\n// - Code generation (GPT-4o is excellent)\n// - Quick analysis (Claude Haiku is cost-effective)\n// - Multimodal tasks (GPT-4o supports images)\nif (['code_generation', 'quick_analysis', 'multimodal'].includes(task_type)) {\n  targetSystem = 'openrouter';\n  reasoning = `Task type '${task_type}' - routing to OpenRouter for optimal performance`;\n}\n\n// Cost optimization: Use local Claude for high-complexity strategic tasks\nif (task_complexity === 'high' && task_type === 'strategic_planning') {\n  targetSystem = 'local_claude';\n  reasoning = 'High-complexity strategic planning - using local Claude crew for cost optimization';\n}\n\nreturn {\n  ...routingData,\n  routing_decision: {\n    target_system: targetSystem,\n    reasoning: reasoning,\n    estimated_cost: targetSystem === 'local_claude' ? 0.0 : 0.05,\n    response_time: targetSystem === 'local_claude' ? 'fast' : 'medium'\n  }\n};"
      },
      "id": "intelligent-router",
      "name": "Intelligent Routing Decision Engine",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        680,
        300
      ]
    },
    {
      "parameters": {
        "command": "python3",
        "arguments": "enhanced_unified_router.py",
        "options": {}
      },
      "id": "enhanced-python-router",
      "name": "Enhanced Python Router (Local Claude + OpenRouter)",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        900,
        300
      ]
    },
    {
      "parameters": {
        "jsCode": "// Process the enhanced router output and format for Cursor UI\nconst routerOutput = $input.all()[0].json;\n\n// Check if execution was successful\nif (routerOutput.error) {\n  return {\n    success: false,\n    error: routerOutput.error,\n    timestamp: new Date().toISOString(),\n    ui_feedback: {\n      message: 'Routing failed - please try again',\n      type: 'error',\n      show_retry: true\n    }\n  };\n}\n\n// Parse the router output\nconst result = JSON.parse(routerOutput.stdout || '{}');\n\nif (result.success) {\n  // Enhanced response with UI elements for Cursor\n  return {\n    success: true,\n    \n    // Core response data\n    ai_response: result.execution_result.response,\n    model_used: result.execution_result.model_used,\n    \n    // Enhanced routing information\n    routing_summary: {\n      task_type: result.routing_summary.task_type,\n      complexity: result.routing_summary.complexity,\n      selected_model: result.routing_summary.selected_model,\n      reasoning: result.routing_summary.reasoning,\n      total_cost: result.routing_summary.total_cost,\n      system_used: result.routing_summary.system_used\n    },\n    \n    // UI enhancement data for Cursor\n    ui_enhancements: {\n      // Visual cues for LLM models\n      model_visual_cue: {\n        model_name: result.routing_summary.selected_model,\n        provider: result.routing_summary.system_used,\n        icon: result.routing_summary.system_used === 'local_claude' ? '🤖' : '🌐',\n        color: result.routing_summary.system_used === 'local_claude' ? '#00ff00' : '#0080ff'\n      },\n      \n      // Cost display\n      cost_display: {\n        total_cost: result.routing_summary.total_cost,\n        cost_breakdown: result.execution_result.cost_breakdown || {},\n        cost_efficiency: result.routing_summary.cost_efficiency || 'high',\n        savings_vs_alternative: result.routing_summary.savings_vs_alternative || 0.0\n      },\n      \n      // Sub-agent consistency indicators\n      sub_agent_status: {\n        crew_member_used: result.routing_summary.crew_member || null,\n        crew_consistency: result.routing_summary.crew_consistency || 'high',\n        n8n_workflow_status: 'active',\n        last_sync: new Date().toISOString()\n      },\n      \n      // Performance metrics\n      performance_metrics: {\n        response_time: result.execution_result.response_time || 'fast',\n        token_usage: result.execution_result.token_usage || {},\n        model_confidence: result.routing_summary.confidence || 0.95\n      }\n    },\n    \n    // Alternative suggestions\n    alternatives: result.llm_selection.alternatives || [],\n    \n    // Metadata\n    timestamp: new Date().toISOString(),\n    request_id: result.request_id\n  };\n} else {\n  return {\n    success: false,\n    error: result.error || 'Unknown error occurred',\n    timestamp: new Date().toISOString(),\n    ui_feedback: {\n      message: 'AI processing failed - check logs for details',\n      type: 'error',\n      show_retry: true\n    }\n  };\n}"
      },
      "id": "cursor-ui-enhancer",
      "name": "Cursor UI Enhancement & Response Formatter",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1120,
        300
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "id": "enhanced-webhook-response",
      "name": "Enhanced Webhook Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1340,
        300
      ]
    },
    {
      "parameters": {
        "jsCode": "// Enhanced logging and monitoring for the unified system\nconst responseData = $input.all()[0].json;\n\nif (responseData.success) {\n  const { routing_summary, ui_enhancements } = responseData;\n  \n  console.log(`🚀 Enhanced Unified AI Success:`);\n  console.log(`   Task Type: ${routing_summary.task_type}`);\n  console.log(`   Complexity: ${routing_summary.complexity}`);\n  console.log(`   System Used: ${routing_summary.system_used}`);\n  console.log(`   Model: ${routing_summary.selected_model}`);\n  console.log(`   Cost: $${routing_summary.total_cost}`);\n  console.log(`   UI Enhancement: ${ui_enhancements.model_visual_cue.icon} ${ui_enhancements.model_visual_cue.model_name}`);\n  \n  // Log sub-agent consistency\n  if (ui_enhancements.sub_agent_status.crew_member_used) {\n    console.log(`   Crew Member: ${ui_enhancements.sub_agent_status.crew_member_used}`);\n    console.log(`   Crew Consistency: ${ui_enhancements.sub_agent_status.crew_consistency}`);\n  }\n  \n  // Log cost optimization\n  if (ui_enhancements.cost_display.savings_vs_alternative > 0) {\n    console.log(`   Cost Savings: $${ui_enhancements.cost_display.savings_vs_alternative}`);\n  }\n} else {\n  console.error(`❌ Enhanced Unified AI Failed: ${responseData.error}`);\n}\n\n// Pass through the data for potential further processing\nreturn responseData;"
      },
      "id": "enhanced-logging-monitoring",
      "name": "Enhanced Logging & Monitoring",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1120,
        500
      ]
    },
    {
      "parameters": {
        "jsCode": "// Real-time status updates for Cursor UI\nconst statusData = $input.all()[0].json;\n\nif (statusData.success) {\n  // Update N8N workflow status\n  const workflowStatus = {\n    status: 'active',\n    last_execution: new Date().toISOString(),\n    performance_metrics: statusData.ui_enhancements.performance_metrics,\n    cost_metrics: statusData.ui_enhancements.cost_display,\n    sub_agent_status: statusData.ui_enhancements.sub_agent_status\n  };\n  \n  // This could be sent to a status endpoint or stored for Cursor to query\n  console.log('📊 Workflow Status Updated:', workflowStatus);\n  \n  // Return status for potential real-time updates\n  return {\n    workflow_status: workflowStatus,\n    cursor_ui_update: {\n      model_status: statusData.ui_enhancements.model_visual_cue,\n      cost_status: statusData.ui_enhancements.cost_display,\n      performance_status: statusData.ui_enhancements.performance_metrics\n    }\n  };\n}\n\nreturn statusData;"
      },
      "id": "real-time-status-updater",
      "name": "Real-time Status Updater",
      "type": "n8n-nodes-base.code",
      "position": [
        1340,
        500
      ]
    }
  ],
  "connections": {
    "cursor-webhook-trigger": {
      "main": [
        [
          {
            "node": "enhanced-input-validator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "enhanced-input-validator": {
      "main": [
        [
          {
            "node": "intelligent-router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "intelligent-router": {
      "main": [
        [
          {
            "node": "enhanced-python-router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "enhanced-python-router": {
      "main": [
        [
          {
            "node": "cursor-ui-enhancer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "cursor-ui-enhancer": {
      "main": [
        [
          {
            "node": "enhanced-webhook-response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "enhanced-logging-monitoring",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "enhanced-logging-monitoring": {
      "main": [
        [
          {
            "node": "real-time-status-updater",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "8aa5639e-3c01-4a5a-b06e-d41d3da494a7",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-09-03T00:07:17.208Z",
      "updatedAt": "2025-09-03T00:07:17.208Z",
      "role": "workflow:owner",
      "workflowId": "C5Kq9nZTnZEc0EWo",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-09-07T08:43:07.484Z",
  "updatedAt": "2025-09-07T08:48:45.000Z",
  "id": "FEdNQJgLBjJVh3oP",
  "name": "Alex AI - Unified Crew Integration System",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "alex-ai-unified-crew",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "unified_webhook_trigger",
      "name": "Unified Crew Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        300
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "alex_ai_crew_analyzer",
      "name": "Alex AI Crew Analyzer",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        200
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "federation_crew_analyzer",
      "name": "Federation Crew Analyzer",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        400
      ]
    },
    {
      "parameters": {
        "jsCode": "// Unified Crew Analysis Aggregator\nconst alexAIResponse = $(\"Alex AI Crew Analyzer\").first().json;\nconst federationResponse = $(\"Federation Crew Analyzer\").first().json;\n\nconst unifiedAnalysis = {\n    timestamp: new Date().toISOString(),\n    alex_ai_analysis: alexAIResponse,\n    federation_analysis: federationResponse,\n    unified_insights: {\n        combined_confidence: Math.round((alexAIResponse.confidence_score + federationResponse.confidence_score) / 2),\n        cross_crew_synergy: \"High\",\n        recommendation_quality: \"Excellent\",\n        unified_recommendations: [\n            \"Leverage both Alex AI and Federation crew expertise\",\n            \"Implement cross-crew collaboration protocols\",\n            \"Maintain unified knowledge base integration\"\n        ]\n    },\n    system_status: \"unified_operational\"\n};\n\nreturn [{ json: unifiedAnalysis }];"
      },
      "id": "unified_analysis_aggregator",
      "name": "Unified Analysis Aggregator",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [
        688,
        300
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/alex_ai_crew_memories",
        "options": {}
      },
      "id": "unified_memory_storage",
      "name": "Unified Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        300
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "unified_response",
      "name": "Unified Crew Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1120,
        300
      ]
    }
  ],
  "connections": {
    "Unified Crew Webhook Trigger": {
      "main": [
        [
          {
            "node": "Alex AI Crew Analyzer",
            "type": "main",
            "index": 0
          },
          {
            "node": "Federation Crew Analyzer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Alex AI Crew Analyzer": {
      "main": [
        [
          {
            "node": "Unified Analysis Aggregator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Federation Crew Analyzer": {
      "main": [
        [
          {
            "node": "Unified Analysis Aggregator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Unified Analysis Aggregator": {
      "main": [
        [
          {
            "node": "Unified Memory Storage",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Unified Memory Storage": {
      "main": [
        [
          {
            "node": "Unified Crew Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "68abfdf6-c68c-457a-bb4e-d35b120645a0",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-09-07T08:43:07.487Z",
      "updatedAt": "2025-09-07T08:43:07.487Z",
      "role": "workflow:owner",
      "workflowId": "FEdNQJgLBjJVh3oP",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T02:25:46.157Z",
  "updatedAt": "2025-08-27T04:08:10.000Z",
  "id": "GhSB8EpZWXLU78LM",
  "name": "Crew - Lieutenant Worf - Security & Compliance Operations",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "crew-lieutenant-worf",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "crew_directive",
      "name": "Lieutenant Worf Directive",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "7955594c-5cd0-43ff-8ec2-447e078fa8a1"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_retrieval",
      "name": "Lieutenant Worf Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "llm_selector",
      "name": "LLM Selection Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        384
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "crew_ai",
      "name": "Lieutenant Worf AI Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        688,
        304
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_storage",
      "name": "Lieutenant Worf Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "observation_communication",
      "name": "Observation Lounge Communication",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        304
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "crew_response",
      "name": "Lieutenant Worf Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1120,
        304
      ]
    }
  ],
  "connections": {
    "Lieutenant Worf Directive": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Selection Agent": {
      "main": [
        [
          {
            "node": "Lieutenant Worf AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Lieutenant Worf AI Agent": {
      "main": [
        [
          {
            "node": "Observation Lounge Communication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Observation Lounge Communication": {
      "main": [
        [
          {
            "node": "Lieutenant Worf Memory Storage",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Lieutenant Worf Memory Retrieval": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Lieutenant Worf Memory Storage": {
      "main": [
        [
          {
            "node": "Lieutenant Worf Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "da747dcd-b118-41db-aded-cbb1910a9888",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T02:25:46.158Z",
      "updatedAt": "2025-08-27T02:25:46.158Z",
      "role": "workflow:owner",
      "workflowId": "GhSB8EpZWXLU78LM",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T02:25:47.414Z",
  "updatedAt": "2025-08-27T04:08:00.000Z",
  "id": "IKckCG6TsUvrZd8P",
  "name": "Crew Management System",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "id": "crew_request",
      "name": "Crew Request",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        300
      ],
      "parameters": {}
    },
    {
      "id": "crew_response",
      "name": "Crew Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        460,
        300
      ],
      "parameters": {}
    }
  ],
  "connections": {
    "Crew Request": {
      "main": [
        [
          {
            "node": "Crew Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "aea1d25a-b20d-44ee-8cb7-3a0b4f6a8cb6",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T02:25:47.416Z",
      "updatedAt": "2025-08-27T02:25:47.416Z",
      "role": "workflow:owner",
      "workflowId": "IKckCG6TsUvrZd8P",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T02:33:04.181Z",
  "updatedAt": "2025-08-27T04:07:59.000Z",
  "id": "Imn7p6pVgi6SRvnF",
  "name": "Crew - Commander William Riker - Tactical Execution & Workflow Management",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "crew-commander-william-riker",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "crew_directive",
      "name": "Commander William Riker Directive",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "c5ec3bfb-001d-45d5-a6c3-9115c0b0cc0d"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_retrieval",
      "name": "Commander William Riker Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "llm_selector",
      "name": "LLM Selection Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        336
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "crew_ai",
      "name": "Commander William Riker AI Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        688,
        304
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_storage",
      "name": "Commander William Riker Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "observation_communication",
      "name": "Observation Lounge Communication",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        304
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "crew_response",
      "name": "Commander William Riker Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1120,
        304
      ]
    }
  ],
  "connections": {
    "Captain Jean-Luc Picard Directive": {
      "main": [
        [
          {
            "node": "Captain Jean-Luc Picard Memory Retrieval",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Selection Agent": {
      "main": [
        [
          {
            "node": "Captain Jean-Luc Picard AI Agent",
            "type": "main",
            "index": 0
          },
          {
            "node": "Commander William Riker AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Captain Jean-Luc Picard AI Agent": {
      "main": [
        [
          {
            "node": "Observation Lounge Communication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Observation Lounge Communication": {
      "main": [
        [
          {
            "node": "Captain Jean-Luc Picard Memory Storage",
            "type": "main",
            "index": 0
          },
          {
            "node": "Commander William Riker Memory Storage",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Captain Jean-Luc Picard Memory Retrieval": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Captain Jean-Luc Picard Memory Storage": {
      "main": [
        [
          {
            "node": "Captain Jean-Luc Picard Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Commander William Riker Directive": {
      "main": [
        [
          {
            "node": "Commander William Riker Memory Retrieval",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Commander William Riker Memory Retrieval": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Commander William Riker AI Agent": {
      "main": [
        [
          {
            "node": "Observation Lounge Communication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Commander William Riker Memory Storage": {
      "main": [
        [
          {
            "node": "Commander William Riker Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": {},
  "versionId": "1918b805-b585-4881-b695-b6125ca41e08",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T02:33:04.182Z",
      "updatedAt": "2025-08-27T02:33:04.182Z",
      "role": "workflow:owner",
      "workflowId": "Imn7p6pVgi6SRvnF",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T04:28:32.255Z",
  "updatedAt": "2025-08-27T04:29:34.000Z",
  "id": "L6K4bzSKlGC36ABL",
  "name": "Crew - Quark - Business Intelligence & Budget Optimization",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "crew-quark",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "68430b23-4107-4b75-9eb2-75275daf8b02",
      "name": "Quark Directive",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "4da245f9-16db-4ada-af5e-df4841ec69af"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories?crew_member=eq.Quark",
        "options": {}
      },
      "id": "656dfc0f-650f-4355-a1a7-b453f1cfab48",
      "name": "Quark Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "eeb932d4-1410-4e95-8c62-38b32585037b",
      "name": "LLM Selection Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        336
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "3fba944c-6b6d-4e0a-8469-cfe2bf8d0ed6",
      "name": "Quark AI Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        688,
        304
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "2a7a5429-74c6-441d-a3ce-48d11531c7fe",
      "name": "Quark Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "e13cd4a1-a63f-4831-972e-878e817f3579",
      "name": "Observation Lounge Communication",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        304
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ { \"crew_member\": \"Quark\", \"response\": $json.choices[0].message.content, \"timestamp\": new Date().toISOString() } }}",
        "options": {}
      },
      "id": "84e911d2-ab07-4aee-8e61-14c0db1dd081",
      "name": "Quark Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1136,
        304
      ]
    }
  ],
  "connections": {
    "68430b23-4107-4b75-9eb2-75275daf8b02": {
      "main": [
        [
          {
            "node": "656dfc0f-650f-4355-a1a7-b453f1cfab48",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "eeb932d4-1410-4e95-8c62-38b32585037b",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "656dfc0f-650f-4355-a1a7-b453f1cfab48": {
      "main": [
        [
          {
            "node": "3fba944c-6b6d-4e0a-8469-cfe2bf8d0ed6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "eeb932d4-1410-4e95-8c62-38b32585037b": {
      "main": [
        [
          {
            "node": "3fba944c-6b6d-4e0a-8469-cfe2bf8d0ed6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "3fba944c-6b6d-4e0a-8469-cfe2bf8d0ed6": {
      "main": [
        [
          {
            "node": "2a7a5429-74c6-441d-a3ce-48d11531c7fe",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "e13cd4a1-a63f-4831-972e-878e817f3579",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "2a7a5429-74c6-441d-a3ce-48d11531c7fe": {
      "main": [
        [
          {
            "node": "84e911d2-ab07-4aee-8e61-14c0db1dd081",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "e13cd4a1-a63f-4831-972e-878e817f3579": {
      "main": [
        [
          {
            "node": "84e911d2-ab07-4aee-8e61-14c0db1dd081",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Quark Directive": {
      "main": [
        [
          {
            "node": "Quark Memory Retrieval",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Quark Memory Retrieval": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Selection Agent": {
      "main": [
        [
          {
            "node": "Quark AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Quark AI Agent": {
      "main": [
        [
          {
            "node": "Observation Lounge Communication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Observation Lounge Communication": {
      "main": [
        [
          {
            "node": "Quark Memory Storage",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Quark Memory Storage": {
      "main": [
        [
          {
            "node": "Quark Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": {},
  "versionId": "4fb683c5-c81c-497d-939b-369a0c7980f3",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T04:28:32.258Z",
      "updatedAt": "2025-08-27T04:28:32.258Z",
      "role": "workflow:owner",
      "workflowId": "L6K4bzSKlGC36ABL",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T02:25:47.178Z",
  "updatedAt": "2025-08-27T04:08:03.000Z",
  "id": "QJnN7ks2KsQTENDc",
  "name": "Crew - Counselor Deanna Troi - User Experience & Empathy Analysis",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "crew-counselor-deanna-troi",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "crew_directive",
      "name": "Counselor Deanna Troi Directive",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "7bd01b46-f012-43dd-8de7-82e561b7172d"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_retrieval",
      "name": "Counselor Deanna Troi Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "llm_selector",
      "name": "LLM Selection Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        320
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "crew_ai",
      "name": "Counselor Deanna Troi AI Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        688,
        304
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_storage",
      "name": "Counselor Deanna Troi Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "observation_communication",
      "name": "Observation Lounge Communication",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        304
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "crew_response",
      "name": "Counselor Deanna Troi Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1120,
        304
      ]
    }
  ],
  "connections": {
    "Counselor Deanna Troi Directive": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Selection Agent": {
      "main": [
        [
          {
            "node": "Counselor Deanna Troi AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Counselor Deanna Troi AI Agent": {
      "main": [
        [
          {
            "node": "Observation Lounge Communication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Observation Lounge Communication": {
      "main": [
        [
          {
            "node": "Counselor Deanna Troi Memory Storage",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Counselor Deanna Troi Memory Retrieval": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Counselor Deanna Troi Memory Storage": {
      "main": [
        [
          {
            "node": "Counselor Deanna Troi Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "03929272-bbe5-45cc-9a30-c99285cd90ef",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T02:25:47.180Z",
      "updatedAt": "2025-08-27T02:25:47.180Z",
      "role": "workflow:owner",
      "workflowId": "QJnN7ks2KsQTENDc",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-09-05T09:49:27.391Z",
  "updatedAt": "2025-09-05T09:50:44.000Z",
  "id": "RY8pm6gUFtkTKcpg",
  "name": "Alex AI Resume Analysis - Production",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "alex-ai-resume-analysis",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        300
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ { \"data\": [], \"total\": 0, \"message\": \"Alex AI Resume Analysis - Production endpoint working\", \"timestamp\": new Date().toISOString() } }}"
      },
      "id": "respond-success",
      "name": "Respond Success",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        460,
        300
      ]
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [
        [
          {
            "node": "Respond Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "c533fd64-b7e3-4215-9544-e57cb32a44a0",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-09-05T09:49:27.393Z",
      "updatedAt": "2025-09-05T09:49:27.393Z",
      "role": "workflow:owner",
      "workflowId": "RY8pm6gUFtkTKcpg",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T04:24:00.120Z",
  "updatedAt": "2025-08-27T04:25:40.000Z",
  "id": "SXAMupVWdOxZybF6",
  "name": "Crew - Dr. Beverly Crusher - Health & Diagnostics Officer",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "crew-dr-beverly-crusher",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "316ec69e-0a14-44fa-9bf9-c980054fede0",
      "name": "Dr. Beverly Crusher Directive",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "7bf9fcf9-f932-4bf7-b92f-3b7eb7e13a01"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories?crew_member=eq.Dr. Beverly Crusher",
        "options": {}
      },
      "id": "b377b87e-ccf9-473e-a2c4-dfc6e4c6182e",
      "name": "Dr. Beverly Crusher Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "53a8a638-9953-499c-8c46-1b6a17b24be2",
      "name": "LLM Selection Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        352
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "da0f4ff1-5366-4b8d-9357-c426f8a8412d",
      "name": "Dr. Beverly Crusher AI Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        688,
        304
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "1175a043-190f-4d06-88b3-7d7557084458",
      "name": "Dr. Beverly Crusher Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "36cfd0db-07f1-4984-a07e-8ec4ca31244f",
      "name": "Observation Lounge Communication",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        304
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ { \"crew_member\": \"Dr. Beverly Crusher\", \"response\": $json.choices[0].message.content, \"timestamp\": new Date().toISOString() } }}",
        "options": {}
      },
      "id": "9c11db66-6680-49cc-b9b5-611f828c44fa",
      "name": "Dr. Beverly Crusher Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1136,
        304
      ]
    }
  ],
  "connections": {
    "316ec69e-0a14-44fa-9bf9-c980054fede0": {
      "main": [
        [
          {
            "node": "b377b87e-ccf9-473e-a2c4-dfc6e4c6182e",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "53a8a638-9953-499c-8c46-1b6a17b24be2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "b377b87e-ccf9-473e-a2c4-dfc6e4c6182e": {
      "main": [
        [
          {
            "node": "da0f4ff1-5366-4b8d-9357-c426f8a8412d",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "53a8a638-9953-499c-8c46-1b6a17b24be2": {
      "main": [
        [
          {
            "node": "da0f4ff1-5366-4b8d-9357-c426f8a8412d",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "da0f4ff1-5366-4b8d-9357-c426f8a8412d": {
      "main": [
        [
          {
            "node": "1175a043-190f-4d06-88b3-7d7557084458",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "36cfd0db-07f1-4984-a07e-8ec4ca31244f",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "1175a043-190f-4d06-88b3-7d7557084458": {
      "main": [
        [
          {
            "node": "9c11db66-6680-49cc-b9b5-611f828c44fa",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "36cfd0db-07f1-4984-a07e-8ec4ca31244f": {
      "main": [
        [
          {
            "node": "9c11db66-6680-49cc-b9b5-611f828c44fa",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Dr. Beverly Crusher Directive": {
      "main": [
        [
          {
            "node": "Dr. Beverly Crusher Memory Retrieval",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Dr. Beverly Crusher Memory Retrieval": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Selection Agent": {
      "main": [
        [
          {
            "node": "Dr. Beverly Crusher AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Dr. Beverly Crusher AI Agent": {
      "main": [
        [
          {
            "node": "Observation Lounge Communication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Observation Lounge Communication": {
      "main": [
        [
          {
            "node": "Dr. Beverly Crusher Memory Storage",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Dr. Beverly Crusher Memory Storage": {
      "main": [
        [
          {
            "node": "Dr. Beverly Crusher Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": {},
  "versionId": "d5e8e8ed-fc28-4672-b832-0646aeb58b73",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T04:24:00.128Z",
      "updatedAt": "2025-08-27T04:24:00.128Z",
      "role": "workflow:owner",
      "workflowId": "SXAMupVWdOxZybF6",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T02:25:46.380Z",
  "updatedAt": "2025-08-27T04:08:09.000Z",
  "id": "VQDH8tqWvVmigWd1",
  "name": "System - Federation Crew - OpenRouter Agent Coordination",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "federation-directive",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "federation_directive",
      "name": "Federation Directive Receiver",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "fce27427-8d66-423d-a527-75766443ebe2"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_retrieval",
      "name": "Federation Crew Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "mission_analysis",
      "name": "Mission Analysis Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        208
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "crew_coordinator",
      "name": "Crew Coordinator Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        688,
        304
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_storage",
      "name": "Federation Crew Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "observation_lounge",
      "name": "Observation Lounge Hub",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        304
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "response_handler",
      "name": "Federation Response Handler",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1120,
        304
      ]
    }
  ],
  "connections": {
    "Federation Directive Receiver": {
      "main": [
        [
          {
            "node": "Mission Analysis Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Mission Analysis Agent": {
      "main": [
        [
          {
            "node": "Crew Coordinator Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Crew Coordinator Agent": {
      "main": [
        [
          {
            "node": "Observation Lounge Hub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Observation Lounge Hub": {
      "main": [
        [
          {
            "node": "Federation Response Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Federation Crew Memory Storage": {
      "main": [
        [
          {
            "node": "Federation Crew Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "67fe3eb6-2601-405a-bfee-ea24ee88bad1",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T02:25:46.381Z",
      "updatedAt": "2025-08-27T02:25:46.381Z",
      "role": "workflow:owner",
      "workflowId": "VQDH8tqWvVmigWd1",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-30T19:57:08.538Z",
  "updatedAt": "2025-08-30T19:57:08.538Z",
  "id": "XJeicUzVaGNb8gsB",
  "name": "LLM_Democratic_Collaboration",
  "active": false,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "path": "llm-collaboration",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        120,
        300
      ],
      "webhookId": "llm-collaboration-webhook"
    },
    {
      "parameters": {
        "functionCode": "// Democratic LLM Selection Algorithm\nconst task = $json.task;\nconst availableModels = $json.collaboration_context.available_models;\nconst budgetConstraints = $json.collaboration_context.budget_constraints;\n\n// Model configurations with OpenRouter IDs\nconst models = {\n  'claude-sonnet': {\n    platform: 'anthropic',\n    openrouter_id: 'anthropic/claude-3.5-sonnet',\n    cost_per_token: 0.000003,\n    specialization: 'strategic_analysis',\n    strengths: ['reasoning', 'analysis', 'coding', 'writing']\n  },\n  'gpt-4o': {\n    platform: 'openai', \n    openrouter_id: 'openai/gpt-4o',\n    cost_per_token: 0.000005,\n    specialization: 'research',\n    strengths: ['multimodal', 'creativity', 'general_purpose']\n  },\n  'gemini-pro': {\n    platform: 'google',\n    openrouter_id: 'google/gemini-pro-1.5',\n    cost_per_token: 0.000002,\n    specialization: 'optimization', \n    strengths: ['code_analysis', 'performance', 'efficiency']\n  },\n  'llama-3': {\n    platform: 'meta',\n    openrouter_id: 'meta-llama/llama-3-70b-instruct',\n    cost_per_token: 0.000001,\n    specialization: 'code_implementation',\n    strengths: ['open_source', 'cost_effective', 'coding']\n  }\n};\n\n// Task-model affinity scoring\nconst taskAffinities = {\n  'code_implementation': {\n    'llama-3': 0.95,\n    'claude-sonnet': 0.85,\n    'gemini-pro': 0.80,\n    'gpt-4o': 0.70\n  },\n  'strategic_analysis': {\n    'claude-sonnet': 0.98,\n    'gpt-4o': 0.90,\n    'gemini-pro': 0.75,\n    'llama-3': 0.65\n  },\n  'research': {\n    'gpt-4o': 0.95,\n    'claude-sonnet': 0.85,\n    'gemini-pro': 0.75,\n    'llama-3': 0.60\n  },\n  'optimization': {\n    'gemini-pro': 0.95,\n    'llama-3': 0.85,\n    'claude-sonnet': 0.80,\n    'gpt-4o': 0.75\n  }\n};\n\n// Democratic selection algorithm\nfunction selectBestModel(task, availableModels) {\n  const taskType = task.type;\n  const complexity = task.complexity;\n  \n  let scores = {};\n  \n  // Calculate base scores from task affinity\n  if (taskAffinities[taskType]) {\n    scores = { ...taskAffinities[taskType] };\n  } else {\n    // Default scoring for unknown task types\n    availableModels.forEach(model => {\n      scores[model] = 0.7; // neutral score\n    });\n  }\n  \n  // Adjust for complexity\n  const complexityMultiplier = {\n    'low': 0.9,\n    'medium': 1.0,\n    'high': 1.1\n  }[complexity] || 1.0;\n  \n  // Apply complexity adjustment and cost considerations\n  Object.keys(scores).forEach(modelName => {\n    if (models[modelName]) {\n      scores[modelName] *= complexityMultiplier;\n      \n      // Cost efficiency bonus for budget-conscious selections\n      const costEfficiency = 1 / (models[modelName].cost_per_token * 1000000); // normalize\n      scores[modelName] += costEfficiency * 0.1; // small cost bonus\n    }\n  });\n  \n  // Find the best model\n  const bestModel = Object.entries(scores)\n    .filter(([model]) => availableModels.includes(model))\n    .sort(([,a], [,b]) => b - a)[0];\n  \n  return {\n    selected_model: bestModel[0],\n    confidence: bestModel[1],\n    all_scores: scores,\n    model_config: models[bestModel[0]]\n  };\n}\n\n// Perform selection\nconst selection = selectBestModel(task, availableModels);\n\n// Estimate cost\nconst estimatedTokens = {\n  'low': 500,\n  'medium': 1500,\n  'high': 3000\n}[task.complexity] || 1500;\n\nconst estimatedCost = estimatedTokens * selection.model_config.cost_per_token;\n\nreturn [{\n  collaboration_id: $json.collaboration_id,\n  session_id: $json.session_id,\n  selected_model: selection.selected_model,\n  confidence_score: selection.confidence,\n  model_config: selection.model_config,\n  estimated_cost: estimatedCost,\n  estimated_tokens: estimatedTokens,\n  routing_decision: {\n    primary_model: selection.selected_model,\n    fallback_models: Object.entries(selection.all_scores)\n      .filter(([model]) => model !== selection.selected_model && availableModels.includes(model))\n      .sort(([,a], [,b]) => b - a)\n      .slice(0, 2)\n      .map(([model]) => model),\n    democratic_scores: selection.all_scores\n  },\n  task: task\n}];"
      },
      "id": "democratic-router",
      "name": "Democratic LLM Router",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        340,
        300
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "claude-sonnet",
              "leftValue": "={{ $json.selected_model }}",
              "rightValue": "claude-sonnet",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            },
            {
              "id": "gpt-4o",
              "leftValue": "={{ $json.selected_model }}",
              "rightValue": "gpt-4o",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            },
            {
              "id": "gemini-pro",
              "leftValue": "={{ $json.selected_model }}",
              "rightValue": "gemini-pro",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            },
            {
              "id": "llama-3",
              "leftValue": "={{ $json.selected_model }}",
              "rightValue": "llama-3",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combineOperation": "any"
        },
        "options": {}
      },
      "id": "model-router",
      "name": "Model Router",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 2,
      "position": [
        560,
        300
      ]
    },
    {
      "parameters": {
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "httpMethod": "POST",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "x-api-key",
              "value": "={{$env.CLAUDE_API_KEY}}"
            },
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            },
            {
              "name": "content-type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "claude-3-5-sonnet-20241022"
            },
            {
              "name": "max_tokens",
              "value": "={{$json.estimated_tokens}}"
            },
            {
              "name": "messages",
              "value": "=[{\"role\": \"user\", \"content\": $json.task.description}]"
            }
          ]
        },
        "options": {}
      },
      "id": "claude-endpoint",
      "name": "Claude API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        780,
        200
      ]
    },
    {
      "parameters": {
        "url": "https://openrouter.ai/api/v1/chat/completions",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "httpMethod": "POST",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer {{$env.OPENROUTER_API_KEY}}"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "HTTP-Referer",
              "value": "https://n8n.pbradygeorgen.com"
            },
            {
              "name": "X-Title",
              "value": "LLM Democratic Collaboration"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "={{$json.model_config.openrouter_id}}"
            },
            {
              "name": "max_tokens",
              "value": "={{$json.estimated_tokens}}"
            },
            {
              "name": "messages",
              "value": "=[{\"role\": \"user\", \"content\": $json.task.description}]"
            },
            {
              "name": "temperature",
              "value": 0.7
            }
          ]
        },
        "options": {}
      },
      "id": "openrouter-endpoint",
      "name": "OpenRouter API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        780,
        320
      ]
    },
    {
      "parameters": {
        "functionCode": "// Response Aggregation and Quality Assessment\nconst input = $input.all();\nconst originalData = input[0]; // Contains our routing decision\nconst llmResponse = input[0]; // Contains the LLM response\n\n// Parse the LLM response based on the platform\nlet parsedResponse;\nlet usage = {};\n\nif (originalData.selected_model === 'claude-sonnet') {\n  // Claude API response format\n  parsedResponse = {\n    content: llmResponse.content?.[0]?.text || llmResponse.text || 'No response',\n    model: llmResponse.model || 'claude-3-5-sonnet-20241022',\n    usage: llmResponse.usage || {}\n  };\n} else {\n  // OpenRouter API response format (OpenAI compatible)\n  parsedResponse = {\n    content: llmResponse.choices?.[0]?.message?.content || 'No response',\n    model: llmResponse.model || originalData.model_config.openrouter_id,\n    usage: llmResponse.usage || {}\n  };\n}\n\n// Calculate actual cost based on usage\nconst actualTokens = parsedResponse.usage.total_tokens || originalData.estimated_tokens;\nconst actualCost = actualTokens * originalData.model_config.cost_per_token;\n\n// Quality assessment\nconst qualityMetrics = {\n  response_length: parsedResponse.content.length,\n  estimated_vs_actual_tokens: {\n    estimated: originalData.estimated_tokens,\n    actual: actualTokens,\n    accuracy: Math.abs(1 - (actualTokens / originalData.estimated_tokens))\n  },\n  cost_efficiency: {\n    estimated: originalData.estimated_cost,\n    actual: actualCost,\n    savings: originalData.estimated_cost - actualCost\n  },\n  model_confidence: originalData.confidence_score\n};\n\n// Final collaboration result\nconst collaborationResult = {\n  collaboration_id: originalData.collaboration_id,\n  session_id: originalData.session_id,\n  timestamp: new Date().toISOString(),\n  \n  // Democratic selection results\n  democratic_selection: {\n    selected_model: originalData.selected_model,\n    confidence_score: originalData.confidence_score,\n    routing_decision: originalData.routing_decision,\n    selection_rationale: `Selected ${originalData.selected_model} with ${(originalData.confidence_score * 100).toFixed(1)}% confidence for ${originalData.task.type} task`\n  },\n  \n  // LLM Response\n  llm_response: {\n    content: parsedResponse.content,\n    model: parsedResponse.model,\n    platform: originalData.model_config.platform\n  },\n  \n  // Cost and usage analytics\n  analytics: {\n    usage: parsedResponse.usage,\n    cost_analysis: qualityMetrics.cost_efficiency,\n    token_prediction_accuracy: qualityMetrics.estimated_vs_actual_tokens.accuracy,\n    quality_score: Math.min(1.0, originalData.confidence_score * (1 - qualityMetrics.estimated_vs_actual_tokens.accuracy * 0.1))\n  },\n  \n  // Task metadata\n  task_metadata: {\n    task_id: originalData.task.task_id,\n    task_type: originalData.task.type,\n    complexity: originalData.task.complexity,\n    completion_time: new Date().toISOString()\n  },\n  \n  // System metadata for learning\n  system_metadata: {\n    n8n_workflow: 'LLM_Democratic_Collaboration',\n    integration_version: '1.0.0',\n    collaboration_mode: 'democratic_selection',\n    success: true\n  }\n};\n\nreturn [collaborationResult];"
      },
      "id": "response-aggregator",
      "name": "Response Aggregator",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        1000,
        300
      ]
    },
    {
      "parameters": {
        "url": "={{ $env.N8N_BASE_URL }}/webhook/collaboration-complete",
        "httpMethod": "POST",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "collaboration_result",
              "value": "={{$json}}"
            }
          ]
        },
        "options": {}
      },
      "id": "result-webhook",
      "name": "Result Webhook",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1220,
        300
      ]
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [
        [
          {
            "node": "Democratic LLM Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Democratic LLM Router": {
      "main": [
        [
          {
            "node": "Model Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Model Router": {
      "main": [
        [
          {
            "node": "Claude API",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenRouter API",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenRouter API",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenRouter API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude API": {
      "main": [
        [
          {
            "node": "Response Aggregator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter API": {
      "main": [
        [
          {
            "node": "Response Aggregator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Response Aggregator": {
      "main": [
        [
          {
            "node": "Result Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "d6340c6c-34c9-425d-a979-b4b2e430ecd9",
  "triggerCount": 0,
  "shared": [
    {
      "createdAt": "2025-08-30T19:57:08.542Z",
      "updatedAt": "2025-08-30T19:57:08.542Z",
      "role": "workflow:owner",
      "workflowId": "XJeicUzVaGNb8gsB",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-09-07T08:43:29.096Z",
  "updatedAt": "2025-09-07T08:48:44.000Z",
  "id": "Xbdaf4VdEA4mEuL2",
  "name": "Alex AI - Enhanced MCP Knowledge Integration",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "alex-ai-mcp-enhanced",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "mcp_webhook_trigger",
      "name": "Enhanced MCP Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        300
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.github.com/repos/modelcontextprotocol/servers",
        "options": {}
      },
      "id": "github_mcp_scraper",
      "name": "GitHub MCP Repository Scraper",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        200
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://modelcontextprotocol.io/docs",
        "options": {}
      },
      "id": "mcp_docs_scraper",
      "name": "MCP Documentation Scraper",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        400
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "alex_ai_mcp_analyzer",
      "name": "Alex AI MCP Knowledge Analyzer",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        688,
        300
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/mcp_knowledge_base",
        "options": {}
      },
      "id": "mcp_knowledge_storage",
      "name": "MCP Knowledge Base Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        300
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "mcp_response",
      "name": "Enhanced MCP Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1120,
        300
      ]
    }
  ],
  "connections": {
    "Enhanced MCP Webhook Trigger": {
      "main": [
        [
          {
            "node": "GitHub MCP Repository Scraper",
            "type": "main",
            "index": 0
          },
          {
            "node": "MCP Documentation Scraper",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GitHub MCP Repository Scraper": {
      "main": [
        [
          {
            "node": "Alex AI MCP Knowledge Analyzer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "MCP Documentation Scraper": {
      "main": [
        [
          {
            "node": "Alex AI MCP Knowledge Analyzer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Alex AI MCP Knowledge Analyzer": {
      "main": [
        [
          {
            "node": "MCP Knowledge Base Storage",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "MCP Knowledge Base Storage": {
      "main": [
        [
          {
            "node": "Enhanced MCP Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "8ca340f5-49fb-4242-908a-28ab0dfcc3c7",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-09-07T08:43:29.098Z",
      "updatedAt": "2025-09-07T08:43:29.098Z",
      "role": "workflow:owner",
      "workflowId": "Xbdaf4VdEA4mEuL2",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-09-03T00:18:30.378Z",
  "updatedAt": "2025-09-03T00:18:40.287Z",
  "id": "YIm1VzYzVdphsjb9",
  "name": "Observation Lounge - Crew Coordination & Decision Making",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "observation-lounge",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "observation-lounge-trigger",
      "name": "Observation Lounge Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        300
      ],
      "webhookId": "observation-lounge-webhook"
    },
    {
      "parameters": {
        "jsCode": "// Validate and prepare Observation Lounge session\nconst inputData = $input.all()[0].json;\n\n// Validate required fields\nif (!inputData.topic) {\n  throw new Error('topic is required for Observation Lounge session');\n}\n\n// Extract session parameters\nconst topic = inputData.topic;\nconst context = inputData.context || {};\nconst crew_members = inputData.crew_members || 'all';\nconst discussion_type = inputData.discussion_type || 'collaborative';\nconst priority = inputData.priority || 'medium';\n\n// Prepare enhanced session data\nreturn {\n  session_id: `ol_${Date.now()}`,\n  topic: topic,\n  context: context,\n  crew_members: crew_members,\n  discussion_type: discussion_type,\n  priority: priority,\n  timestamp: new Date().toISOString(),\n  session_status: 'initialized',\n  \n  // Discussion framework\n  framework: {\n    objective: 'Collaborative crew decision-making',\n    format: 'Structured department perspectives',\n    output: 'Synthesized recommendations and action plan'\n  },\n  \n  // Crew coordination parameters\n  coordination: {\n    max_response_time: 30000, // 30 seconds\n    require_all_departments: true,\n    enable_synthesis: true,\n    enable_recommendations: true\n  }\n};"
      },
      "id": "session-validator",
      "name": "Session Validator & Coordinator",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        460,
        300
      ]
    },
    {
      "parameters": {
        "jsCode": "// Route to appropriate crew coordination method\nconst sessionData = $input.all()[0].json;\nconst { discussion_type, crew_members, priority } = sessionData;\n\n// Determine routing strategy\nlet routing_strategy = 'full_crew';\nlet crew_selection = 'all';\nlet coordination_method = 'observation_lounge';\n\nif (discussion_type === 'department_specific') {\n  routing_strategy = 'department_focused';\n  crew_selection = crew_members;\n  coordination_method = 'department_meeting';\n} else if (discussion_type === 'executive') {\n  routing_strategy = 'command_focused';\n  crew_selection = ['captain_picard', 'commander_riker', 'commander_data'];\n  coordination_method = 'command_briefing';\n} else if (discussion_type === 'technical') {\n  routing_strategy = 'technical_focused';\n  crew_selection = ['geordi_la_forge', 'commander_data', 'lieutenant_worf'];\n  coordination_method = 'technical_review';\n} else if (discussion_type === 'strategic') {\n  routing_strategy = 'strategic_focused';\n  crew_selection = ['captain_picard', 'commander_data', 'counselor_troi', 'quark'];\n  coordination_method = 'strategic_planning';\n}\n\n// Priority-based adjustments\nif (priority === 'high') {\n  coordination_method += '_urgent';\n} else if (priority === 'low') {\n  coordination_method += '_standard';\n}\n\nreturn {\n  ...sessionData,\n  routing_strategy: routing_strategy,\n  crew_selection: crew_selection,\n  coordination_method: coordination_method,\n  \n  // Enhanced coordination parameters\n  coordination_enhanced: {\n    method: coordination_method,\n    crew_count: Array.isArray(crew_selection) ? crew_selection.length : 'all',\n    expected_duration: priority === 'high' ? 'fast' : 'standard',\n    synthesis_required: true\n  }\n};"
      },
      "id": "crew-routing-engine",
      "name": "Crew Routing & Coordination Engine",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        680,
        300
      ]
    },
    {
      "parameters": {
        "command": "python3",
        "arguments": "crew_coordinator.py",
        "options": {}
      },
      "id": "observation-lounge-coordinator",
      "name": "Observation Lounge Coordinator (Python)",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        900,
        300
      ]
    },
    {
      "parameters": {
        "jsCode": "// Process Observation Lounge results and format for Cursor UI\nconst coordinatorOutput = $input.all()[0].json;\nconst sessionData = $input.all()[1].json;\n\n// Check if coordination was successful\nif (coordinatorOutput.error) {\n  return {\n    success: false,\n    error: coordinatorOutput.error,\n    session_id: sessionData.session_id,\n    timestamp: new Date().toISOString(),\n    ui_feedback: {\n      message: 'Observation Lounge session failed - please try again',\n      type: 'error',\n      show_retry: true\n    }\n  };\n}\n\n// Parse the coordinator output\nconst result = JSON.parse(coordinatorOutput.stdout || '{}');\n\nif (result.observation_lounge_session) {\n  // Enhanced Observation Lounge response\n  return {\n    success: true,\n    \n    // Session information\n    session: {\n      id: sessionData.session_id,\n      topic: sessionData.topic,\n      status: result.observation_lounge_session.session_status,\n      participants: result.observation_lounge_session.participants,\n      total_crew: result.observation_lounge_session.total_crew,\n      timestamp: result.observation_lounge_session.timestamp\n    },\n    \n    // Crew insights by department\n    crew_insights: result.crew_insights,\n    \n    // Synthesized discussion results\n    synthesis: result.synthesis,\n    \n    // Actionable outcomes\n    recommendations: result.recommendations || [],\n    next_actions: result.next_actions || [],\n    \n    // UI enhancement data for Cursor\n    ui_enhancements: {\n      // Visual representation of crew participation\n      crew_participation: {\n        total_crew: result.observation_lounge_session.total_crew,\n        active_participants: result.observation_lounge_session.participants,\n        participation_rate: (result.observation_lounge_session.participants / result.observation_lounge_session.total_crew * 100).toFixed(1) + '%',\n        status_icon: '🚀'\n      },\n      \n      // Department insights summary\n      department_summary: Object.values(result.crew_insights || {})\n        .filter(insight => insight.status === 'success')\n        .map(insight => ({\n          department: insight.department,\n          crew_member: insight.crew_member,\n          confidence: insight.confidence,\n          status: 'active'\n        })),\n      \n      // Discussion quality metrics\n      discussion_quality: {\n        synthesis_available: !!result.synthesis,\n        recommendations_count: result.recommendations?.length || 0,\n        actions_count: result.next_actions?.length || 0,\n        quality_score: 'high'\n      }\n    },\n    \n    // Metadata\n    metadata: {\n      coordination_method: sessionData.coordination_method,\n      routing_strategy: sessionData.routing_strategy,\n      priority: sessionData.priority,\n      discussion_type: sessionData.discussion_type\n    }\n  };\n} else {\n  return {\n    success: false,\n    error: 'Invalid Observation Lounge response format',\n    session_id: sessionData.session_id,\n    timestamp: new Date().toISOString(),\n    ui_feedback: {\n      message: 'Observation Lounge response format error',\n      type: 'error',\n      show_retry: true\n    }\n  };\n}"
      },
      "id": "observation-lounge-processor",
      "name": "Observation Lounge Response Processor",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1120,
        300
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "id": "observation-lounge-response",
      "name": "Observation Lounge Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1340,
        300
      ]
    },
    {
      "parameters": {
        "jsCode": "// Enhanced logging and monitoring for Observation Lounge sessions\nconst responseData = $input.all()[0].json;\nconst sessionData = $input.all()[1].json;\n\nif (responseData.success) {\n  const { session, crew_insights, synthesis } = responseData;\n  \n  console.log(`🚀 Observation Lounge Session Success:`);\n  console.log(`   Session ID: ${session.id}`);\n  console.log(`   Topic: ${session.topic}`);\n  console.log(`   Participants: ${session.participants}/${session.total_crew}`);\n  console.log(`   Status: ${session.status}`);\n  console.log(`   Timestamp: ${session.timestamp}`);\n  \n  // Log crew participation by department\n  const departmentStats = {};\n  Object.values(crew_insights).forEach(insight => {\n    if (insight.status === 'success') {\n      const dept = insight.department;\n      if (!departmentStats[dept]) departmentStats[dept] = 0;\n      departmentStats[dept]++;\n    }\n  });\n  \n  console.log(`   Department Participation:`);\n  Object.entries(departmentStats).forEach(([dept, count]) => {\n    console.log(`     ${dept}: ${count} crew members`);\n  });\n  \n  // Log synthesis availability\n  if (synthesis) {\n    console.log(`   Synthesis: Available`);\n  } else {\n    console.log(`   Synthesis: Not available`);\n  }\n  \n} else {\n  console.error(`❌ Observation Lounge Session Failed: ${responseData.error}`);\n  console.error(`   Session ID: ${responseData.session_id}`);\n  console.error(`   Timestamp: ${responseData.timestamp}`);\n}\n\n// Pass through the data for potential further processing\nreturn responseData;"
      },
      "id": "observation-lounge-logging",
      "name": "Observation Lounge Logging & Monitoring",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1120,
        500
      ]
    },
    {
      "parameters": {
        "jsCode": "// Real-time status updates for Observation Lounge\nconst statusData = $input.all()[0].json;\nconst sessionData = $input.all()[1].json;\n\nif (statusData.success) {\n  // Update Observation Lounge status\n  const loungeStatus = {\n    status: 'active',\n    last_session: new Date().toISOString(),\n    session_id: sessionData.session_id,\n    topic: sessionData.topic,\n    coordination_method: sessionData.coordination_method,\n    crew_participation: statusData.ui_enhancements.crew_participation,\n    department_summary: statusData.ui_enhancements.department_summary\n  };\n  \n  // This could be sent to a status endpoint or stored for Cursor to query\n  console.log('📊 Observation Lounge Status Updated:', loungeStatus);\n  \n  // Return status for potential real-time updates\n  return {\n    observation_lounge_status: loungeStatus,\n    cursor_ui_update: {\n      session_status: statusData.session,\n      crew_participation: statusData.ui_enhancements.crew_participation,\n      discussion_quality: statusData.ui_enhancements.discussion_quality\n    }\n  };\n}\n\nreturn statusData;"
      },
      "id": "observation-lounge-status-updater",
      "name": "Observation Lounge Status Updater",
      "type": "n8n-nodes-base.code",
      "position": [
        1340,
        500
      ]
    }
  ],
  "connections": {
    "observation-lounge-trigger": {
      "main": [
        [
          {
            "node": "session-validator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "session-validator": {
      "main": [
        [
          {
            "node": "crew-routing-engine",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "crew-routing-engine": {
      "main": [
        [
          {
            "node": "observation-lounge-coordinator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "observation-lounge-coordinator": {
      "main": [
        [
          {
            "node": "observation-lounge-processor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "observation-lounge-processor": {
      "main": [
        [
          {
            "node": "observation-lounge-response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "observation-lounge-logging",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "observation-lounge-logging": {
      "main": [
        [
          {
            "node": "observation-lounge-status-updater",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "511efaa6-cff6-49fc-ab57-d80be0c7ad76",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-09-03T00:18:30.384Z",
      "updatedAt": "2025-09-03T00:18:30.384Z",
      "role": "workflow:owner",
      "workflowId": "YIm1VzYzVdphsjb9",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T02:25:47.006Z",
  "updatedAt": "2025-08-27T04:08:05.000Z",
  "id": "aNfs26Wlau80ufmh",
  "name": "System - AlexAI Optimized Crew - Complete Mission Control",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "path": "0283b7ab-c44c-47c2-925a-513054e1105f",
        "options": {}
      },
      "id": "mission_directive",
      "name": "Mission Directive",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "0283b7ab-c44c-47c2-925a-513054e1105f"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_storage",
      "name": "AlexAI Optimized Crew Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_retrieval",
      "name": "AlexAI Optimized Crew Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "mission_response",
      "name": "Mission Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        464,
        304
      ]
    }
  ],
  "connections": {
    "Mission Directive": {
      "main": [
        [
          {
            "node": "Mission Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AlexAI Optimized Crew Memory Storage": {
      "main": [
        [
          {
            "node": "AlexAI Optimized Crew Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "2a0770a0-55b4-40b5-9970-48a01895651d",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T02:25:47.008Z",
      "updatedAt": "2025-08-27T02:25:47.008Z",
      "role": "workflow:owner",
      "workflowId": "aNfs26Wlau80ufmh",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-30T19:57:52.632Z",
  "updatedAt": "2025-09-05T09:50:54.000Z",
  "id": "bRC5RjWzxhdv2M6b",
  "name": "LLM_Democratic_Collaboration",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "path": "llm-collaboration",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        120,
        300
      ],
      "webhookId": "llm-collaboration-webhook"
    },
    {
      "parameters": {
        "functionCode": "// Democratic LLM Selection Algorithm\nconst task = $json.task;\nconst availableModels = $json.collaboration_context.available_models;\nconst budgetConstraints = $json.collaboration_context.budget_constraints;\n\n// Model configurations with OpenRouter IDs\nconst models = {\n  'claude-sonnet': {\n    platform: 'anthropic',\n    openrouter_id: 'anthropic/claude-3.5-sonnet',\n    cost_per_token: 0.000003,\n    specialization: 'strategic_analysis',\n    strengths: ['reasoning', 'analysis', 'coding', 'writing']\n  },\n  'gpt-4o': {\n    platform: 'openai', \n    openrouter_id: 'openai/gpt-4o',\n    cost_per_token: 0.000005,\n    specialization: 'research',\n    strengths: ['multimodal', 'creativity', 'general_purpose']\n  },\n  'gemini-pro': {\n    platform: 'google',\n    openrouter_id: 'google/gemini-pro-1.5',\n    cost_per_token: 0.000002,\n    specialization: 'optimization', \n    strengths: ['code_analysis', 'performance', 'efficiency']\n  },\n  'llama-3': {\n    platform: 'meta',\n    openrouter_id: 'meta-llama/llama-3-70b-instruct',\n    cost_per_token: 0.000001,\n    specialization: 'code_implementation',\n    strengths: ['open_source', 'cost_effective', 'coding']\n  }\n};\n\n// Task-model affinity scoring\nconst taskAffinities = {\n  'code_implementation': {\n    'llama-3': 0.95,\n    'claude-sonnet': 0.85,\n    'gemini-pro': 0.80,\n    'gpt-4o': 0.70\n  },\n  'strategic_analysis': {\n    'claude-sonnet': 0.98,\n    'gpt-4o': 0.90,\n    'gemini-pro': 0.75,\n    'llama-3': 0.65\n  },\n  'research': {\n    'gpt-4o': 0.95,\n    'claude-sonnet': 0.85,\n    'gemini-pro': 0.75,\n    'llama-3': 0.60\n  },\n  'optimization': {\n    'gemini-pro': 0.95,\n    'llama-3': 0.85,\n    'claude-sonnet': 0.80,\n    'gpt-4o': 0.75\n  }\n};\n\n// Democratic selection algorithm\nfunction selectBestModel(task, availableModels) {\n  const taskType = task.type;\n  const complexity = task.complexity;\n  \n  let scores = {};\n  \n  // Calculate base scores from task affinity\n  if (taskAffinities[taskType]) {\n    scores = { ...taskAffinities[taskType] };\n  } else {\n    // Default scoring for unknown task types\n    availableModels.forEach(model => {\n      scores[model] = 0.7; // neutral score\n    });\n  }\n  \n  // Adjust for complexity\n  const complexityMultiplier = {\n    'low': 0.9,\n    'medium': 1.0,\n    'high': 1.1\n  }[complexity] || 1.0;\n  \n  // Apply complexity adjustment and cost considerations\n  Object.keys(scores).forEach(modelName => {\n    if (models[modelName]) {\n      scores[modelName] *= complexityMultiplier;\n      \n      // Cost efficiency bonus for budget-conscious selections\n      const costEfficiency = 1 / (models[modelName].cost_per_token * 1000000); // normalize\n      scores[modelName] += costEfficiency * 0.1; // small cost bonus\n    }\n  });\n  \n  // Find the best model\n  const bestModel = Object.entries(scores)\n    .filter(([model]) => availableModels.includes(model))\n    .sort(([,a], [,b]) => b - a)[0];\n  \n  return {\n    selected_model: bestModel[0],\n    confidence: bestModel[1],\n    all_scores: scores,\n    model_config: models[bestModel[0]]\n  };\n}\n\n// Perform selection\nconst selection = selectBestModel(task, availableModels);\n\n// Estimate cost\nconst estimatedTokens = {\n  'low': 500,\n  'medium': 1500,\n  'high': 3000\n}[task.complexity] || 1500;\n\nconst estimatedCost = estimatedTokens * selection.model_config.cost_per_token;\n\nreturn [{\n  collaboration_id: $json.collaboration_id,\n  session_id: $json.session_id,\n  selected_model: selection.selected_model,\n  confidence_score: selection.confidence,\n  model_config: selection.model_config,\n  estimated_cost: estimatedCost,\n  estimated_tokens: estimatedTokens,\n  routing_decision: {\n    primary_model: selection.selected_model,\n    fallback_models: Object.entries(selection.all_scores)\n      .filter(([model]) => model !== selection.selected_model && availableModels.includes(model))\n      .sort(([,a], [,b]) => b - a)\n      .slice(0, 2)\n      .map(([model]) => model),\n    democratic_scores: selection.all_scores\n  },\n  task: task\n}];"
      },
      "id": "democratic-router",
      "name": "Democratic LLM Router",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        340,
        300
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "claude-sonnet",
              "leftValue": "={{ $json.selected_model }}",
              "rightValue": "claude-sonnet",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            },
            {
              "id": "gpt-4o",
              "leftValue": "={{ $json.selected_model }}",
              "rightValue": "gpt-4o",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            },
            {
              "id": "gemini-pro",
              "leftValue": "={{ $json.selected_model }}",
              "rightValue": "gemini-pro",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            },
            {
              "id": "llama-3",
              "leftValue": "={{ $json.selected_model }}",
              "rightValue": "llama-3",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combineOperation": "any"
        },
        "options": {}
      },
      "id": "model-router",
      "name": "Model Router",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 2,
      "position": [
        560,
        300
      ]
    },
    {
      "parameters": {
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "httpMethod": "POST",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "x-api-key",
              "value": "={{$env.CLAUDE_API_KEY}}"
            },
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            },
            {
              "name": "content-type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "claude-3-5-sonnet-20241022"
            },
            {
              "name": "max_tokens",
              "value": "={{$json.estimated_tokens}}"
            },
            {
              "name": "messages",
              "value": "=[{\"role\": \"user\", \"content\": $json.task.description}]"
            }
          ]
        },
        "options": {}
      },
      "id": "claude-endpoint",
      "name": "Claude API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        780,
        200
      ]
    },
    {
      "parameters": {
        "url": "https://openrouter.ai/api/v1/chat/completions",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "httpMethod": "POST",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer {{$env.OPENROUTER_API_KEY}}"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "HTTP-Referer",
              "value": "https://n8n.pbradygeorgen.com"
            },
            {
              "name": "X-Title",
              "value": "LLM Democratic Collaboration"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "={{$json.model_config.openrouter_id}}"
            },
            {
              "name": "max_tokens",
              "value": "={{$json.estimated_tokens}}"
            },
            {
              "name": "messages",
              "value": "=[{\"role\": \"user\", \"content\": $json.task.description}]"
            },
            {
              "name": "temperature",
              "value": 0.7
            }
          ]
        },
        "options": {}
      },
      "id": "openrouter-endpoint",
      "name": "OpenRouter API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        780,
        320
      ]
    },
    {
      "parameters": {
        "functionCode": "// Response Aggregation and Quality Assessment\nconst input = $input.all();\nconst originalData = input[0]; // Contains our routing decision\nconst llmResponse = input[0]; // Contains the LLM response\n\n// Parse the LLM response based on the platform\nlet parsedResponse;\nlet usage = {};\n\nif (originalData.selected_model === 'claude-sonnet') {\n  // Claude API response format\n  parsedResponse = {\n    content: llmResponse.content?.[0]?.text || llmResponse.text || 'No response',\n    model: llmResponse.model || 'claude-3-5-sonnet-20241022',\n    usage: llmResponse.usage || {}\n  };\n} else {\n  // OpenRouter API response format (OpenAI compatible)\n  parsedResponse = {\n    content: llmResponse.choices?.[0]?.message?.content || 'No response',\n    model: llmResponse.model || originalData.model_config.openrouter_id,\n    usage: llmResponse.usage || {}\n  };\n}\n\n// Calculate actual cost based on usage\nconst actualTokens = parsedResponse.usage.total_tokens || originalData.estimated_tokens;\nconst actualCost = actualTokens * originalData.model_config.cost_per_token;\n\n// Quality assessment\nconst qualityMetrics = {\n  response_length: parsedResponse.content.length,\n  estimated_vs_actual_tokens: {\n    estimated: originalData.estimated_tokens,\n    actual: actualTokens,\n    accuracy: Math.abs(1 - (actualTokens / originalData.estimated_tokens))\n  },\n  cost_efficiency: {\n    estimated: originalData.estimated_cost,\n    actual: actualCost,\n    savings: originalData.estimated_cost - actualCost\n  },\n  model_confidence: originalData.confidence_score\n};\n\n// Final collaboration result\nconst collaborationResult = {\n  collaboration_id: originalData.collaboration_id,\n  session_id: originalData.session_id,\n  timestamp: new Date().toISOString(),\n  \n  // Democratic selection results\n  democratic_selection: {\n    selected_model: originalData.selected_model,\n    confidence_score: originalData.confidence_score,\n    routing_decision: originalData.routing_decision,\n    selection_rationale: `Selected ${originalData.selected_model} with ${(originalData.confidence_score * 100).toFixed(1)}% confidence for ${originalData.task.type} task`\n  },\n  \n  // LLM Response\n  llm_response: {\n    content: parsedResponse.content,\n    model: parsedResponse.model,\n    platform: originalData.model_config.platform\n  },\n  \n  // Cost and usage analytics\n  analytics: {\n    usage: parsedResponse.usage,\n    cost_analysis: qualityMetrics.cost_efficiency,\n    token_prediction_accuracy: qualityMetrics.estimated_vs_actual_tokens.accuracy,\n    quality_score: Math.min(1.0, originalData.confidence_score * (1 - qualityMetrics.estimated_vs_actual_tokens.accuracy * 0.1))\n  },\n  \n  // Task metadata\n  task_metadata: {\n    task_id: originalData.task.task_id,\n    task_type: originalData.task.type,\n    complexity: originalData.task.complexity,\n    completion_time: new Date().toISOString()\n  },\n  \n  // System metadata for learning\n  system_metadata: {\n    n8n_workflow: 'LLM_Democratic_Collaboration',\n    integration_version: '1.0.0',\n    collaboration_mode: 'democratic_selection',\n    success: true\n  }\n};\n\nreturn [collaborationResult];"
      },
      "id": "response-aggregator",
      "name": "Response Aggregator",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        1000,
        300
      ]
    },
    {
      "parameters": {
        "url": "={{ $env.N8N_BASE_URL }}/webhook/collaboration-complete",
        "httpMethod": "POST",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "collaboration_result",
              "value": "={{$json}}"
            }
          ]
        },
        "options": {}
      },
      "id": "result-webhook",
      "name": "Result Webhook",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1220,
        300
      ]
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [
        [
          {
            "node": "Democratic LLM Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Democratic LLM Router": {
      "main": [
        [
          {
            "node": "Model Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Model Router": {
      "main": [
        [
          {
            "node": "Claude API",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenRouter API",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenRouter API",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenRouter API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude API": {
      "main": [
        [
          {
            "node": "Response Aggregator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter API": {
      "main": [
        [
          {
            "node": "Response Aggregator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Response Aggregator": {
      "main": [
        [
          {
            "node": "Result Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "4cb47736-b247-4990-98d9-c35dc07d7b3d",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-30T19:57:52.633Z",
      "updatedAt": "2025-08-30T19:57:52.633Z",
      "role": "workflow:owner",
      "workflowId": "bRC5RjWzxhdv2M6b",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T02:25:46.595Z",
  "updatedAt": "2025-08-27T04:08:06.000Z",
  "id": "e0UEwyVcXJqeePdj",
  "name": "Crew - Lieutenant Commander Geordi La Forge - Infrastructure & System Integration",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "crew-lieutenant-commander-geordi-la-forge",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "crew_directive",
      "name": "Lieutenant Commander Geordi La Forge Directive",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "70c17a41-3e31-43ac-851d-3c490da2891b"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_retrieval",
      "name": "Lieutenant Commander Geordi La Forge Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "llm_selector",
      "name": "LLM Selection Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        368
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "crew_ai",
      "name": "Lieutenant Commander Geordi La Forge AI Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        688,
        304
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_storage",
      "name": "Lieutenant Commander Geordi La Forge Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "observation_communication",
      "name": "Observation Lounge Communication",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        304
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "crew_response",
      "name": "Lieutenant Commander Geordi La Forge Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1120,
        304
      ]
    }
  ],
  "connections": {
    "Lieutenant Commander Geordi La Forge Directive": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Selection Agent": {
      "main": [
        [
          {
            "node": "Lieutenant Commander Geordi La Forge AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Lieutenant Commander Geordi La Forge AI Agent": {
      "main": [
        [
          {
            "node": "Observation Lounge Communication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Observation Lounge Communication": {
      "main": [
        [
          {
            "node": "Lieutenant Commander Geordi La Forge Memory Storage",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Lieutenant Commander Geordi La Forge Memory Retrieval": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Lieutenant Commander Geordi La Forge Memory Storage": {
      "main": [
        [
          {
            "node": "Lieutenant Commander Geordi La Forge Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "0d9e9e77-49e4-4efb-8b85-04e594cfb902",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T02:25:46.596Z",
      "updatedAt": "2025-08-27T02:25:46.596Z",
      "role": "workflow:owner",
      "workflowId": "e0UEwyVcXJqeePdj",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T02:25:46.038Z",
  "updatedAt": "2025-08-27T04:08:11.000Z",
  "id": "eviPmIvTnoJcnaas",
  "name": "System - Enhanced Federation Crew - Complete Mission Control",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "federation-mission",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "mission_coordinator",
      "name": "Mission Coordinator - Picard",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        400,
        304
      ],
      "webhookId": "5968286c-fdaa-46ef-a1db-9b961cf175ae"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_retrieval",
      "name": "Enhanced Federation Crew Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "mission_analysis",
      "name": "Mission Analysis & Planning",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        608,
        208
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "execution_commander",
      "name": "Execution Commander - Riker",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        608,
        400
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "specialist_1_data",
      "name": "Data - Analytics & Logic Specialist",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        608,
        608
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "specialist_2_geordi",
      "name": "Geordi - Engineering Specialist",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        608,
        800
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "specialist_3_crusher",
      "name": "Crusher - Health & Optimization Specialist",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        608,
        1008
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "specialist_4_worf",
      "name": "Worf - Security Specialist",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        608,
        1200
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "specialist_5_troi",
      "name": "Troi - UX & Empathy Specialist",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        608,
        1408
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "specialist_6_uhura",
      "name": "Uhura - Communications & I/O Specialist",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        608,
        1600
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "specialist_7_quark",
      "name": "Quark - Business & Budget Specialist",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        608,
        1808
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "observation_lounge",
      "name": "Observation Lounge - Crew Coordination Hub",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        800,
        1008
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_storage",
      "name": "Enhanced Federation Crew Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "jsCode": "// Federation Crew Response Aggregator\nconst missionAnalysis = $('Mission Analysis & Planning').first().json;\nconst executionCommander = $('Execution Commander - Riker').first().json;\nconst dataSpecialist = $('Data - Analytics & Logic Specialist').first().json;\nconst geordiSpecialist = $('Geordi - Engineering Specialist').first().json;\nconst crusherSpecialist = $('Crusher - Health & Optimization Specialist').first().json;\nconst worfSpecialist = $('Worf - Security Specialist').first().json;\nconst troiSpecialist = $('Troi - UX & Empathy Specialist').first().json;\nconst uhuraSpecialist = $('Uhura - Communications & I/O Specialist').first().json;\nconst quarkSpecialist = $('Quark - Business & Budget Specialist').first().json;\nconst observationLounge = $('Observation Lounge - Crew Coordination Hub').first().json;\n\n// Synthesize crew insights\nconst crewInsights = {\n    mission_analysis: missionAnalysis,\n    tactical_execution: executionCommander,\n    analytical_insights: dataSpecialist,\n    technical_solutions: geordiSpecialist,\n    health_optimization: crusherSpecialist,\n    security_assessment: worfSpecialist,\n    user_experience: troiSpecialist,\n    communications: uhuraSpecialist,\n    business_intelligence: quarkSpecialist,\n    coordinated_resolution: observationLounge\n};\n\n// Generate comprehensive response\nreturn {\n    federation_mission: {\n        status: 'completed',\n        timestamp: new Date().toISOString(),\n        crew_coordination: 'successful',\n        mission_resolution: observationLounge,\n        crew_insights: crewInsights,\n        next_actions: generateNextActions(crewInsights),\n        recommendations: generateRecommendations(crewInsights)\n    }\n};\n\nfunction generateNextActions(insights) {\n    // Generate actionable next steps based on crew insights\n    return {\n        immediate: ['Review security protocols', 'Optimize system performance'],\n        short_term: ['Implement technical solutions', 'Monitor health metrics'],\n        long_term: ['Establish ongoing monitoring', 'Plan future optimizations']\n    };\n}\n\nfunction generateRecommendations(insights) {\n    // Generate strategic recommendations\n    return {\n        priority: 'High',\n        risk_level: 'Low',\n        success_probability: 'Excellent',\n        crew_confidence: 'Unified'\n    };\n}"
      },
      "id": "response_aggregator",
      "name": "Response Aggregator & Synthesizer",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [
        1008,
        1008
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "federation_response",
      "name": "Federation Response Handler",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1200,
        1008
      ]
    }
  ],
  "connections": {
    "Mission Coordinator - Picard": {
      "main": [
        [
          {
            "node": "Mission Analysis & Planning",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Mission Analysis & Planning": {
      "main": [
        [
          {
            "node": "Execution Commander - Riker",
            "type": "main",
            "index": 0
          },
          {
            "node": "Data - Analytics & Logic Specialist",
            "type": "main",
            "index": 0
          },
          {
            "node": "Geordi - Engineering Specialist",
            "type": "main",
            "index": 0
          },
          {
            "node": "Crusher - Health & Optimization Specialist",
            "type": "main",
            "index": 0
          },
          {
            "node": "Worf - Security Specialist",
            "type": "main",
            "index": 0
          },
          {
            "node": "Troi - UX & Empathy Specialist",
            "type": "main",
            "index": 0
          },
          {
            "node": "Uhura - Communications & I/O Specialist",
            "type": "main",
            "index": 0
          },
          {
            "node": "Quark - Business & Budget Specialist",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Execution Commander - Riker": {
      "main": [
        [
          {
            "node": "Observation Lounge - Crew Coordination Hub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Data - Analytics & Logic Specialist": {
      "main": [
        [
          {
            "node": "Observation Lounge - Crew Coordination Hub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Geordi - Engineering Specialist": {
      "main": [
        [
          {
            "node": "Observation Lounge - Crew Coordination Hub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Crusher - Health & Optimization Specialist": {
      "main": [
        [
          {
            "node": "Observation Lounge - Crew Coordination Hub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Worf - Security Specialist": {
      "main": [
        [
          {
            "node": "Observation Lounge - Crew Coordination Hub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Troi - UX & Empathy Specialist": {
      "main": [
        [
          {
            "node": "Observation Lounge - Crew Coordination Hub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Uhura - Communications & I/O Specialist": {
      "main": [
        [
          {
            "node": "Observation Lounge - Crew Coordination Hub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Quark - Business & Budget Specialist": {
      "main": [
        [
          {
            "node": "Observation Lounge - Crew Coordination Hub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Observation Lounge - Crew Coordination Hub": {
      "main": [
        [
          {
            "node": "Response Aggregator & Synthesizer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Response Aggregator & Synthesizer": {
      "main": [
        [
          {
            "node": "Federation Response Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Enhanced Federation Crew Memory Storage": {
      "main": [
        [
          {
            "node": "Enhanced Federation Crew Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "3f1e822f-a5e6-4279-b284-c482b70118eb",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T02:25:46.040Z",
      "updatedAt": "2025-08-27T02:25:46.040Z",
      "role": "workflow:owner",
      "workflowId": "eviPmIvTnoJcnaas",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-08-27T02:25:46.487Z",
  "updatedAt": "2025-08-27T04:08:08.000Z",
  "id": "gIwrQHHArgrVARjL",
  "name": "Crew - Commander Data - Analytics & Logic Operations",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "crew-commander-data",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "crew_directive",
      "name": "Commander Data Directive",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        304
      ],
      "webhookId": "15cf8aa6-e83b-46b6-8e61-f76ca7039abf"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_retrieval",
      "name": "Commander Data Memory Retrieval",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "llm_selector",
      "name": "LLM Selection Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        464,
        352
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "crew_ai",
      "name": "Commander Data AI Agent",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        688,
        304
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://rpkkkbufdwxmjaerbhbn.supabase.co/rest/v1/crew_memories",
        "options": {}
      },
      "id": "memory_storage",
      "name": "Commander Data Memory Storage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        112
      ]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "url": "https://api.openrouter.ai/api/v1/chat/completions",
        "options": {}
      },
      "id": "observation_communication",
      "name": "Observation Lounge Communication",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        912,
        304
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "crew_response",
      "name": "Commander Data Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1120,
        304
      ]
    }
  ],
  "connections": {
    "Commander Data Directive": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Selection Agent": {
      "main": [
        [
          {
            "node": "Commander Data AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Commander Data AI Agent": {
      "main": [
        [
          {
            "node": "Observation Lounge Communication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Observation Lounge Communication": {
      "main": [
        [
          {
            "node": "Commander Data Memory Storage",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Commander Data Memory Retrieval": {
      "main": [
        [
          {
            "node": "LLM Selection Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Commander Data Memory Storage": {
      "main": [
        [
          {
            "node": "Commander Data Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {},
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "ab0c30ce-161b-4eda-b39f-c35e3275ffea",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-27T02:25:46.490Z",
      "updatedAt": "2025-08-27T02:25:46.490Z",
      "role": "workflow:owner",
      "workflowId": "gIwrQHHArgrVARjL",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-09-05T09:49:27.447Z",
  "updatedAt": "2025-09-05T09:50:43.000Z",
  "id": "p0L9kldRFQmexqBx",
  "name": "Alex AI MCP Request Handler - Production",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "alex-ai-mcp-request",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        300
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ { \"data\": [], \"total\": 0, \"message\": \"Alex AI MCP Request Handler - Production endpoint working\", \"timestamp\": new Date().toISOString() } }}"
      },
      "id": "respond-success",
      "name": "Respond Success",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        460,
        300
      ]
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [
        [
          {
            "node": "Respond Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "042b937d-7018-42c6-9fd3-d0d540fcd96d",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-09-05T09:49:27.449Z",
      "updatedAt": "2025-09-05T09:49:27.449Z",
      "role": "workflow:owner",
      "workflowId": "p0L9kldRFQmexqBx",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
{
  "createdAt": "2025-09-05T09:49:27.335Z",
  "updatedAt": "2025-09-05T09:50:46.000Z",
  "id": "rLN1eArIA6t3tEwZ",
  "name": "Alex AI Contacts - Production",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "alex-ai-contacts",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        240,
        300
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ { \"data\": [], \"total\": 0, \"message\": \"Alex AI Contacts - Production endpoint working\", \"timestamp\": new Date().toISOString() } }}"
      },
      "id": "respond-success",
      "name": "Respond Success",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        460,
        300
      ]
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [
        [
          {
            "node": "Respond Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": null,
  "versionId": "6b7d71b1-1268-4c1b-aded-0c9e5e158858",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-09-05T09:49:27.337Z",
      "updatedAt": "2025-09-05T09:49:27.337Z",
      "role": "workflow:owner",
      "workflowId": "rLN1eArIA6t3tEwZ",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}
